{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j75Kznd8In73"
   },
   "source": [
    "# \ud83c\udfae Training AI to Play Wordle with Reinforcement Learning\n",
    "\n",
    "### Using Prime Intellect Verifiers + GRPO\n",
    "\n",
    "**Workshop Goal:** See how we can train language models to play games using RL, from rollout generation to training.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Wordle?\n",
    "\n",
    "Wordle is a perfect RL testbed:\n",
    "- \u2705 **Clear rewards**: Win/lose, # of guesses\n",
    "- \u2705 **Multi-turn reasoning**: Must use feedback from previous guesses\n",
    "- \u2705 **Strategic thinking**: Vowel placement, common letters, elimination\n",
    "- \u2705 **Fast feedback**: Games are short, rewards are immediate\n",
    "\n",
    "## What We'll Cover\n",
    "\n",
    "1. \ud83c\udfaf See a model play Wordle (live!)\n",
    "2. \ud83d\udcca Analyze 100 pre-generated games\n",
    "3. \ud83e\udde0 Understand the RL training loop\n",
    "4. \ud83d\ude80 Where to go next\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24r2iRtrIn74"
   },
   "source": [
    "## \ud83d\udd27 Setup (Pre-installed)\n",
    "\n",
    "**Note:** All dependencies are pre-installed in this notebook. If you're running this yourself later, execute these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoI7ABq2In75",
    "outputId": "3212535b-3780-4d87-ccdb-0f0ae8edb88e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting uv\n",
      "  Downloading uv-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Downloading uv-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: uv\n",
      "Successfully installed uv-0.9.3\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run if starting fresh:\n",
    "# !pip install uv\n",
    "# !pip install -q openai datasets pandas matplotlib seaborn\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def ensure_openai_api_key(env_var: str = 'OPENAI_API_KEY'):\n",
    "    \"\"\"Return the OpenAI API key if available, otherwise print a warning.\"\"\"\n",
    "    key = os.environ.get(env_var)\n",
    "    if key:\n",
    "        return key.strip()\n",
    "\n",
    "    try:\n",
    "        from google.colab import userdata  # type: ignore\n",
    "    except ModuleNotFoundError:\n",
    "        userdata = None\n",
    "    else:\n",
    "        key = userdata.get(env_var)\n",
    "        if key:\n",
    "            os.environ[env_var] = key.strip()\n",
    "            return key.strip()\n",
    "\n",
    "    print('\u26a0\ufe0f  OPENAI_API_KEY is not set. Cells that call external APIs will be skipped.')\n",
    "    print(\"    Set the key with os.environ['OPENAI_API_KEY'] = 'sk-...' or store it in Colab userdata.\")\n",
    "    return None\n",
    "\n",
    "OPENAI_API_KEY = ensure_openai_api_key()\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install 'verifiers[dev]'"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pG8waIFMOBlj",
    "outputId": "3d528647-f104-41b8-c20e-1c73419233a1"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting verifiers[dev]\n",
      "  Downloading verifiers-0.1.5.post0-py3-none-any.whl.metadata (22 kB)\n",
      "\u001b[33mWARNING: verifiers 0.1.5.post0 does not provide the extra 'dev'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from verifiers[dev]) (4.0.0)\n",
      "Requirement already satisfied: jinja2>=3.1.6 in /usr/local/lib/python3.12/dist-packages (from verifiers[dev]) (3.1.6)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from verifiers[dev]) (1.6.0)\n",
      "Collecting openai-agents>=0.0.7 (from verifiers[dev])\n",
      "  Downloading openai_agents-0.3.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: openai>=1.108.1 in /usr/local/lib/python3.12/dist-packages (from verifiers[dev]) (1.109.1)\n",
      "Collecting prime-sandboxes>=0.1.0 (from verifiers[dev])\n",
      "  Downloading prime_sandboxes-0.1.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pydantic>=2.11.9 in /usr/local/lib/python3.12/dist-packages (from verifiers[dev]) (2.11.10)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from verifiers[dev]) (2.32.4)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from verifiers[dev]) (13.9.4)\n",
      "Collecting textual (from verifiers[dev])\n",
      "  Downloading textual-6.3.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.1.6->verifiers[dev]) (3.0.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.108.1->verifiers[dev]) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.108.1->verifiers[dev]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.108.1->verifiers[dev]) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.108.1->verifiers[dev]) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.108.1->verifiers[dev]) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai>=1.108.1->verifiers[dev]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai>=1.108.1->verifiers[dev]) (4.15.0)\n",
      "Collecting griffe<2,>=1.5.6 (from openai-agents>=0.0.7->verifiers[dev])\n",
      "  Downloading griffe-1.14.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: mcp<2,>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents>=0.0.7->verifiers[dev]) (1.16.0)\n",
      "Collecting types-requests<3,>=2.0 (from openai-agents>=0.0.7->verifiers[dev])\n",
      "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.9->verifiers[dev]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.9->verifiers[dev]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.9->verifiers[dev]) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->verifiers[dev]) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->verifiers[dev]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->verifiers[dev]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->verifiers[dev]) (2025.10.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets->verifiers[dev]) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets->verifiers[dev]) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->verifiers[dev]) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->verifiers[dev]) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets->verifiers[dev]) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->verifiers[dev]) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->verifiers[dev]) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->verifiers[dev]) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets->verifiers[dev]) (0.35.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets->verifiers[dev]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets->verifiers[dev]) (6.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->verifiers[dev]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->verifiers[dev]) (2.19.2)\n",
      "Requirement already satisfied: platformdirs<5,>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from textual->verifiers[dev]) (4.5.0)\n",
      "Collecting rich (from verifiers[dev])\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->verifiers[dev]) (3.13.0)\n",
      "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents>=0.0.7->verifiers[dev])\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.108.1->verifiers[dev]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.108.1->verifiers[dev]) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets->verifiers[dev]) (1.1.10)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->verifiers[dev]) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual->verifiers[dev]) (2.0.3)\n",
      "Requirement already satisfied: mdit-py-plugins>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual->verifiers[dev]) (0.5.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents>=0.0.7->verifiers[dev]) (0.4.2)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents>=0.0.7->verifiers[dev]) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents>=0.0.7->verifiers[dev]) (2.11.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents>=0.0.7->verifiers[dev]) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents>=0.0.7->verifiers[dev]) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents>=0.0.7->verifiers[dev]) (0.48.0)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents>=0.0.7->verifiers[dev]) (0.37.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->verifiers[dev]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->verifiers[dev]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->verifiers[dev]) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->verifiers[dev]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->verifiers[dev]) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->verifiers[dev]) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->verifiers[dev]) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->verifiers[dev]) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->verifiers[dev]) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->verifiers[dev]) (1.22.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents>=0.0.7->verifiers[dev]) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents>=0.0.7->verifiers[dev]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents>=0.0.7->verifiers[dev]) (0.27.1)\n",
      "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.12/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual->verifiers[dev]) (1.0.3)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents>=0.0.7->verifiers[dev]) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->verifiers[dev]) (1.17.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents>=0.0.7->verifiers[dev]) (8.3.0)\n",
      "Downloading openai_agents-0.3.3-py3-none-any.whl (210 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m210.9/210.9 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prime_sandboxes-0.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading textual-6.3.0-py3-none-any.whl (711 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m711.5/711.5 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading verifiers-0.1.5.post0-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading griffe-1.14.0-py3-none-any.whl (144 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: types-requests, colorama, rich, griffe, prime-sandboxes, textual, openai-agents, verifiers\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.9.4\n",
      "    Uninstalling rich-13.9.4:\n",
      "      Successfully uninstalled rich-13.9.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.24.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed colorama-0.4.6 griffe-1.14.0 openai-agents-0.3.3 prime-sandboxes-0.1.0 rich-14.2.0 textual-6.3.0 types-requests-2.32.4.20250913 verifiers-0.1.5.post0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9170dcd0"
   },
   "source": [
    "!pip install -q verifiers"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NqOFSAaXIn75",
    "outputId": "e9872db7-7470-4f24-a996-a4bf34a8c4cc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 All imports successful!\n",
      "\ud83d\udce6 Verifiers version: 0.1.5.post0\n"
     ]
    }
   ],
   "source": [
    "import verifiers as vf\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset, Dataset\n",
    "import json\n",
    "\n",
    "# Set style for prettier plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"\u2705 All imports successful!\")\n",
    "print(f\"\ud83d\udce6 Verifiers version: {vf.__version__ if hasattr(vf, '__version__') else 'installed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KU5AUvvIn75"
   },
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udce6 PRE-WORKSHOP: Data Generation\n",
    "\n",
    "**\u26a0\ufe0f RUN THIS SECTION THE NIGHT BEFORE YOUR WORKSHOP \u26a0\ufe0f**\n",
    "\n",
    "This section generates 100 Wordle rollouts that will be used in the workshop demo.\n",
    "\n",
    "**Why pre-generate?**\n",
    "- Takes 5-10 minutes to generate 100 games\n",
    "- Avoids API rate limits during live demo\n",
    "- Ensures consistent data for analysis\n",
    "\n",
    "**What you'll get:**\n",
    "- `wordle_rollouts_100.json` - Full dataset of 100 games\n",
    "- `wordle_rollouts_summary.json` - Quick stats\n",
    "- `best_examples.json` - Top 5 performances\n",
    "- `worst_examples.json` - Bottom 5 performances\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfu8KndkIn75"
   },
   "source": [
    "### Step 1: Check Your Setup\n",
    "\n",
    "Make sure you have:\n",
    "- \u2705 OpenAI API key set (or another provider)\n",
    "- \u2705 Sufficient API credits (~$0.50 for 100 games with gpt-5-mini-2025-08-07)\n",
    "- \u2705 Google Drive mounted (to save files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7NiwnXcIn75",
    "outputId": "f8b72263-6440-44f8-b375-77ed5295d1e6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "\u2705 Files will be saved to: /content/drive/MyDrive/wordle_workshop_data\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive to save generated data\n",
    "from pathlib import Path\n",
    "\n",
    "def resolve_save_dir(default_subdir: str = 'wordle_workshop_data') -> Path:\n",
    "    try:\n",
    "        from google.colab import drive  # type: ignore\n",
    "    except ModuleNotFoundError:\n",
    "        save_dir = Path.cwd() / default_subdir\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'\u26a0\ufe0f google.colab not available. Saving files locally to: {save_dir.resolve()}')\n",
    "        return save_dir\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    save_dir = Path('/content/drive/MyDrive') / default_subdir\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f'\u2705 Files will be saved to: {save_dir}')\n",
    "    return save_dir\n",
    "\n",
    "SAVE_DIR = resolve_save_dir()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19-BmaCDIn75"
   },
   "source": [
    "### Step 2: Generate the Rollouts\n",
    "\n",
    "**This will take ~5-10 minutes depending on API speed.**\n",
    "\n",
    "The script will:\n",
    "1. Load the Wordle environment\n",
    "2. Generate 100 games with gpt-5-mini-2025-08-07\n",
    "3. Compute statistics\n",
    "4. Save 4 JSON files"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!vf-install wordle --from-repo"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1JMq3uYanT1",
    "outputId": "5fa7845d-1e15-42ee-a081-09bc5afa40e6"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mwordle==0.1.4                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mverifiers==0.1.5.post0                                                        \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnltk==3.9.1                                                                   \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtextarena==0.7.4                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mdatasets==4.0.0                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mjinja2==3.1.6                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnest-asyncio==1.6.0                                                           \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mopenai-agents==0.3.3                                                          \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mopenai==1.109.1                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mprime-sandboxes==0.1.0                                                        \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpydantic==2.11.10                                                             \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpydantic-core==2.33.2                                                         \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mrequests==2.32.4                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mrich==14.2.0                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtextual==6.3.0                                                                \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mclick==8.3.0                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mjoblib==1.5.2                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mregex==2024.11.6                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mmultidict==6.7.0                                                              \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m82 packages\u001b[0m \u001b[2min 78ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m82 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Colab userdata access is handled inside ensure_openai_api_key().\n"
   ],
   "metadata": {
    "id": "Ac6-_jaudwNR"
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955,
     "referenced_widgets": [
      "d8487334cacf4bc18c043cb3fff7a31f",
      "d6e6af2d57b14bc5826df9f9ac5c5a20",
      "fd44b76f3e50457aba89436873fcca3f",
      "0df4b5c5e0374194b220b6c315d991bf",
      "48bb1595d70744499b5992634ea2dbf6",
      "b76f60bb1b3a4c029040f013033594f2",
      "ba29ff45af1a4700aa3a174d123a73ae",
      "bcda4921900040349cbbf26e225d7f5b",
      "a7cb62b4a8fa412697c8ac9c230e3f9e",
      "6cf9bec6cefc4b3498c451da0fe3d4ba",
      "1865b7ac50eb490a83d673a3bdd1b05c",
      "85340771c3c94d9cb6a5bdce624f5228",
      "702307b6888a4570aba5364d2bbe565e",
      "48cdeeba412f4644808fe363e66ffebe",
      "b71c7d34e41a47998f989168b69827df",
      "b79ebc3baef6428ca154f804ddcc779c",
      "2c8b64ce48c34a32aa2e2e8c1b3eede0",
      "f2b2edbc444a4177a5fc1fdf223995ad",
      "d929b7805ea9435c93cbdf6e09bae952",
      "4285ef90325d4aefaf4d6e21737a47c6",
      "81cadd9b05554c58a6ef553d5ab2982f",
      "65772ee789124f1da6b372a7b6fe389f",
      "da86cce46da248d2af339bd3a99a6e36",
      "dc9a355e4ac94f36906946a723931052",
      "24e28c54b8414018af8b6ba8295e20a3",
      "a17dac2863784ffeaf878c449c405579",
      "12cb493d188347bf9a0c7a170de7af08",
      "ba3e8de604dc4760bdb9ffda4e80bdde",
      "e364ec640c2040c6b95bb2ae694e311b",
      "fb328dad754a4df4870feceffa68fa06",
      "1a7737e7dc4344e4a81bb228a15038eb",
      "d4cf6ae130394fb9a249fb6a1c877b4a",
      "f69f2d48ca5343b490ebbbfb155aa066"
     ]
    },
    "id": "mD8ruKAVIn76",
    "outputId": "5feab25f-79a2-4b52-932f-9153e6136fee"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025-10-17 04:58:53 - verifiers.utils.env_utils - INFO - Loading environment: wordle\n",
      "2025-10-17 04:58:53 - verifiers.utils.env_utils - INFO - Using default args: num_eval_examples=20, num_train_examples=2000, use_think=True\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83c\udfae Starting Wordle Rollout Generation\n",
      "============================================================\n",
      "Target: 100 games\n",
      "Started at: 04:58:53\n",
      "\n",
      "\ud83d\udce6 Loading Wordle environment...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8487334cacf4bc18c043cb3fff7a31f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85340771c3c94d9cb6a5bdce624f5228"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025-10-17 04:58:55 - verifiers.utils.env_utils - INFO - Successfully loaded environment 'wordle'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Environment loaded! Dataset has 2000 words\n",
      "\n",
      "\ud83c\udfb2 Generating rollouts...\n",
      "\u23f3 This will take about 5-10 minutes depending on API speed\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Running 20 rollouts (interleaved): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [02:26<00:00,  7.34s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\u2705 Rollout generation complete!\n",
      "\n",
      "\ud83d\udcbe Saving data files...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da86cce46da248d2af339bd3a99a6e36"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Saved: wordle_rollouts_100.json\n",
      "\u2705 Saved: wordle_rollouts_summary.json\n",
      "\u2705 Saved: best_examples.json\n",
      "\u2705 Saved: worst_examples.json\n",
      "\n",
      "============================================================\n",
      "\ud83c\udf89 ALL DONE!\n",
      "============================================================\n",
      "\n",
      "\ud83d\udcca Summary Statistics:\n",
      "  \u2022 Success rate: 100.0%\n",
      "  \u2022 Average reward: 1.99\n",
      "  \u2022 Median reward: 2.03\n",
      "\n",
      "\ud83d\udcc1 Files created:\n",
      "  1. wordle_rollouts_100.json (full dataset)\n",
      "  2. wordle_rollouts_summary.json (quick stats)\n",
      "  3. best_examples.json (top 5 games)\n",
      "  4. worst_examples.json (bottom 5 games)\n",
      "\n",
      "\ud83d\udcbe All files saved to: /content/drive/MyDrive/wordle_workshop_data\n",
      "\n",
      "\ud83d\ude80 Next steps:\n",
      "  1. These files are now in your Google Drive\n",
      "  2. Run the verification cell below\n",
      "  3. You're ready for the workshop!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import verifiers as vf\n",
    "from openai import OpenAI\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def generate_workshop_data(num_examples=100, save_dir=SAVE_DIR):\n",
    "    \"\"\"\n",
    "    Generate Wordle rollouts and save to files for workshop.\n",
    "\n",
    "    Args:\n",
    "        num_examples: Number of Wordle games to generate (default: 100)\n",
    "        save_dir: Directory to save the output files\n",
    "    \"\"\"\n",
    "\n",
    "    api_key = ensure_openai_api_key()\n",
    "    if not api_key:\n",
    "        print('\u26a0\ufe0f Skipping rollout generation because no API key is configured.')\n",
    "        return None, None\n",
    "\n",
    "    print('\ud83c\udfae Starting Wordle Rollout Generation')\n",
    "    print('=' * 60)\n",
    "    print(f'Target: {num_examples} games')\n",
    "    print(f\"Started at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print()\n",
    "\n",
    "    # Load environment\n",
    "    print('\ud83d\udce6 Loading Wordle environment...')\n",
    "    wordle_env = vf.load_environment('wordle')\n",
    "    print(f'\u2705 Environment loaded! Dataset has {len(wordle_env.dataset)} words')\n",
    "    print()\n",
    "\n",
    "    # Setup client\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    # Generate rollouts\n",
    "    print('\ud83c\udfb2 Generating rollouts...')\n",
    "    print('\u23f3 This will take about 5-10 minutes depending on API speed')\n",
    "    print()\n",
    "\n",
    "    results = wordle_env.evaluate(\n",
    "        client=client,\n",
    "        model='gpt-5-mini-2025-08-07',\n",
    "        num_examples=num_examples,\n",
    "        rollouts_per_example=1,\n",
    "        max_concurrent=10  # Parallel requests for speed\n",
    "    )\n",
    "\n",
    "    print()\n",
    "    print('\u2705 Rollout generation complete!')\n",
    "    print()\n",
    "\n",
    "    # Convert to dataset format\n",
    "    dataset = wordle_env.make_dataset(results)\n",
    "\n",
    "    # Save raw data\n",
    "    print('\ud83d\udcbe Saving data files...')\n",
    "\n",
    "    save_path = Path(save_dir)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1. Full dataset as JSON\n",
    "    dataset.to_json(\n",
    "        save_path / 'wordle_rollouts_100.json',\n",
    "        orient='records',\n",
    "        lines=True,  # JSON Lines format\n",
    "        force_ascii=False\n",
    "    )\n",
    "    print('\u2705 Saved: wordle_rollouts_100.json')\n",
    "\n",
    "    # 2. Summary statistics\n",
    "    df = dataset.to_pandas()\n",
    "\n",
    "    # Calculate stats\n",
    "    success_rate = df['reward'].apply(lambda x: x > 0.5).mean()\n",
    "    avg_reward = df['reward'].mean()\n",
    "\n",
    "    # Estimate guesses from reward (approximate)\n",
    "    df['estimated_guesses'] = df['reward'].apply(\n",
    "        lambda r: int(6 - (r * 5)) if r > 0 else 6\n",
    "    )\n",
    "\n",
    "    summary = {\n",
    "        'total_games': len(df),\n",
    "        'success_rate': float(success_rate),\n",
    "        'average_reward': float(avg_reward),\n",
    "        'reward_distribution': {\n",
    "            'min': float(df['reward'].min()),\n",
    "            '25th': float(df['reward'].quantile(0.25)),\n",
    "            'median': float(df['reward'].median()),\n",
    "            '75th': float(df['reward'].quantile(0.75)),\n",
    "            'max': float(df['reward'].max()),\n",
    "        },\n",
    "        'guess_distribution': df['estimated_guesses'].value_counts().to_dict(),\n",
    "        'generated_at': datetime.now().isoformat(),\n",
    "    }\n",
    "\n",
    "    with open(save_path / 'wordle_rollouts_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print('\u2705 Saved: wordle_rollouts_summary.json')\n",
    "\n",
    "    # 3. Best examples\n",
    "    best_5 = df.nlargest(5, 'reward')\n",
    "    best_examples = []\n",
    "    for _, row in best_5.iterrows():\n",
    "        best_examples.append({\n",
    "            'word': row.get('answer', 'Unknown'),\n",
    "            'reward': float(row['reward']),\n",
    "            'prompt': row['prompt'][:200] + '...' if len(row['prompt']) > 200 else row['prompt'],\n",
    "            'completion': row['completion'][:300] + '...' if len(row['completion']) > 300 else row['completion'],\n",
    "        })\n",
    "\n",
    "    with open(save_path / 'best_examples.json', 'w') as f:\n",
    "        json.dump(best_examples, f, indent=2)\n",
    "    print('\u2705 Saved: best_examples.json')\n",
    "\n",
    "    # 4. Worst examples\n",
    "    worst_5 = df.nsmallest(5, 'reward')\n",
    "    worst_examples = []\n",
    "    for _, row in worst_5.iterrows():\n",
    "        worst_examples.append({\n",
    "            'word': row.get('answer', 'Unknown'),\n",
    "            'reward': float(row['reward']),\n",
    "            'prompt': row['prompt'][:200] + '...' if len(row['prompt']) > 200 else row['prompt'],\n",
    "            'completion': row['completion'][:300] + '...' if len(row['completion']) > 300 else row['completion'],\n",
    "        })\n",
    "\n",
    "    with open(save_path / 'worst_examples.json', 'w') as f:\n",
    "        json.dump(worst_examples, f, indent=2)\n",
    "    print('\u2705 Saved: worst_examples.json')\n",
    "\n",
    "    print()\n",
    "    print('=' * 60)\n",
    "    print('\ud83c\udf89 ALL DONE!')\n",
    "    print('=' * 60)\n",
    "    print()\n",
    "    print('\ud83d\udcca Summary Statistics:')\n",
    "    print(f'  \u2022 Success rate: {success_rate*100:.1f}%')\n",
    "    print(f'  \u2022 Average reward: {avg_reward:.2f}')\n",
    "    print(f\"  \u2022 Median reward: {summary['reward_distribution']['median']:.2f}\")\n",
    "    print()\n",
    "    print('\ud83d\udcc1 Files created:')\n",
    "    print('  1. wordle_rollouts_100.json (full dataset)')\n",
    "    print('  2. wordle_rollouts_summary.json (quick stats)')\n",
    "    print('  3. best_examples.json (top 5 games)')\n",
    "    print('  4. worst_examples.json (bottom 5 games)')\n",
    "    print()\n",
    "    print(f'\ud83d\udcbe All files saved to: {save_path}')\n",
    "    print()\n",
    "    print('\ud83d\ude80 Next steps:')\n",
    "    print('  1. These files are now in your Google Drive or local folder')\n",
    "    print('  2. Run the verification cell below')\n",
    "    print(\"  3. You're ready for the workshop!\")\n",
    "    print()\n",
    "\n",
    "    return summary, dataset\n",
    "\n",
    "# Run the generation\n",
    "summary, dataset = generate_workshop_data(num_examples=100)\n",
    "if dataset is None:\n",
    "    print('\u2139\ufe0f Generation skipped \u2014 continue once an API key is available.')\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "rollouts_path = Path(SAVE_DIR) / 'wordle_rollouts_100.json'\n",
    "if not rollouts_path.exists():\n",
    "    print(f'\u26a0\ufe0f Skipping JSON reformatting because {rollouts_path} was not found.')\n",
    "else:\n",
    "    # Read JSONL file\n",
    "    with open(rollouts_path, 'r') as f:\n",
    "        data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "    # Write as JSON array\n",
    "    with open(rollouts_path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f'\u2705 Reformatted {rollouts_path.name} into standard JSON array.')\n"
   ],
   "metadata": {
    "id": "ffSFm1S-j3tI"
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2pircPPIn76"
   },
   "source": [
    "### Step 3: Verify the Data\n",
    "\n",
    "Quick sanity check to make sure everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcKLbzU0In76",
    "outputId": "29d60f6f-4483-4c19-996a-c486c08930e1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udd0d Verifying generated data...\n",
      "\n",
      "\u2705 Found 20 rollouts in main file\n",
      "\u2705 Summary stats look good: 100.0% success rate\n",
      "\u2705 Best example has reward: 2.25\n",
      "\u2705 Worst example has reward: 1.65\n",
      "\n",
      "\u2705 All files verified successfully!\n",
      "\n",
      "\ud83c\udf89 You're all set for the workshop!\n",
      "\ud83d\udcdd Remember to update the data loading cells below to use these files.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "def verify_generated_data(save_dir=SAVE_DIR):\n",
    "    \"\"\"Quick sanity check on generated data.\"\"\"\n",
    "    print('\ud83d\udd0d Verifying generated data...')\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        # Check main dataset\n",
    "        with open(Path(save_dir) / 'wordle_rollouts_100.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "        print(f'\u2705 Found {len(data)} rollouts in main file')\n",
    "\n",
    "        # Check summary\n",
    "        with open(Path(save_dir) / 'wordle_rollouts_summary.json', 'r') as f:\n",
    "            summary = json.load(f)\n",
    "        print(f\"\u2705 Summary stats look good: {summary['success_rate']*100:.1f}% success rate\")\n",
    "\n",
    "        # Check best examples\n",
    "        with open(Path(save_dir) / 'best_examples.json', 'r') as f:\n",
    "            best = json.load(f)\n",
    "        print(f\"\u2705 Best example has reward: {best[0]['reward']:.2f}\")\n",
    "\n",
    "        # Check worst examples\n",
    "        with open(Path(save_dir) / 'worst_examples.json', 'r') as f:\n",
    "            worst = json.load(f)\n",
    "        print(f\"\u2705 Worst example has reward: {worst[0]['reward']:.2f}\")\n",
    "\n",
    "        print()\n",
    "        print('\u2705 All files verified successfully!')\n",
    "        print()\n",
    "        print(\"\ud83c\udf89 You're all set for the workshop!\")\n",
    "        print('\ud83d\udcdd Remember to update the data loading cells below to use these files.')\n",
    "        return True\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f'\u274c Missing file: {e}')\n",
    "        print()\n",
    "        print('Troubleshooting:')\n",
    "        print('  1. Make sure the generation cell completed successfully.')\n",
    "        print('  2. Confirm SAVE_DIR is pointing to the right folder.')\n",
    "        print('  3. Re-run the generation once your API key is set.')\n",
    "        return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'\u274c Error verifying data: {e}')\n",
    "        print()\n",
    "        print('Troubleshooting:')\n",
    "        print('  1. Check that the files were created in the save directory')\n",
    "        print('  2. Make sure the generation completed successfully')\n",
    "        print('  3. Try running the generation cell again')\n",
    "        return False\n",
    "\n",
    "# Verify the data\n",
    "verify_generated_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osLAUTtTIn76"
   },
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udcca Step 4: Pre-RL Baseline Evaluation\n",
    "\n",
    "**Run this section to establish baseline performance before training.**\n",
    "\n",
    "This will:\n",
    "- Load the base Gemma 3 1B model\n",
    "- Run 20 Wordle games to measure baseline\n",
    "- Save baseline metrics for comparison\n",
    "\n",
    "**Time:** ~5-10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYg0UxrVIn76",
    "outputId": "b6b110b4-def4-4b49-abac-fa5e678d0250"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m506.3/506.3 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m265.6/265.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m153.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "bigframes 2.24.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-45' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-41' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-33' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-34' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-39' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-40' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-48' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-51' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-50' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-36' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-44' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-46' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-47' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-35' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-37' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-43' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-49' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-52' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-38' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-74' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-75' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-76' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-77' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-78' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-82' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-81' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-79' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-83' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-80' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-73' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-64' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-70' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-66' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-71' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-69' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-68' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-67' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-72' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py:75> exception=AuthenticationError(\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 485, in run_one\n",
      "    comp_i, state_i = await self.rollout(\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/multiturn_env.py\", line 97, in rollout\n",
      "    response = await self.get_model_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 291, in get_model_response\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/verifiers/envs/environment.py\", line 264, in get_model_response\n",
      "    response = await client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u2705 Training dependencies ready\n"
     ]
    }
   ],
   "source": [
    "# Install training dependencies if not already installed\n",
    "!pip install -q \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install -q xformers trl peft accelerate bitsandbytes\n",
    "\n",
    "print(\"\u2705 Training dependencies ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545,
     "referenced_widgets": [
      "d104cd9d4e73427c8d934a9f3a020998",
      "299f9b75282a46309b9618dab03bf43c",
      "78150d407c67489796e5371cd677cf75",
      "b4f4f51b1a5d405e9388d27192fc4993",
      "ea4ba96a8803451e9304fbe65697a47b",
      "2c622d0f4bfb461ca03a2aca278ad1a6",
      "9dac553cb8274dc7870d4cd3ba9f56b7",
      "eaba662ea88848dcba2cd6e9fe83bed3",
      "c52f6016a69d49ca9947d63994abb22a",
      "97c5f8533075456bbf6000b8404f1c7d",
      "23384c56e3594a77863f162ed4f48cb3",
      "64a73585c8ce4b1f853ae0767a26659a",
      "b721c8ab9588451086f96879d278eb08",
      "711ca702e7514f1daedb02768454d5e6",
      "619707ad366d4e68aff1aa20a9571900",
      "2c90095da6ac439ea1215668fc053844",
      "892631eea14943b3ac7175aff6324f51",
      "1790c66a66964839baf4b60d1716b04f",
      "6edad5f8eb094ce99c4f10ad246095f7",
      "f85e801c3c3740dea7ae16a7b1c10c25",
      "d57a545740d94bd7927fa18d6949916b",
      "2caa4d5891a742f48c87ef5ec7159d0d",
      "898c18a560e0492294e3aea8fe5e0b74",
      "56787004933648359d84ec0fc8b92f93",
      "8a236f3cbe71453f9ed5e7bfe3a96d43",
      "fc93d02a1c48436bb58489f3f3889ca8",
      "06f9ef1a891b43b3b0ab5b501ba46cee",
      "a2ce806739a040138057f1f96a3cb821",
      "78d0b74ef1804fbf825f355e44eba529",
      "69aba70e1ad849f7ad0b83bd9c75f6f5",
      "0ade3026d8b240988549269931519e1d",
      "8ffbea536bf443088f7b1c8a2ec66899",
      "35867bc0b0cc4045bb42612bfbfecf48",
      "91b86561f4104483950975ef86392d99",
      "5abe9f047c6a41ae993c573eaed0d545",
      "2111de1165994cdd92de7c4bcada70c5",
      "b5e9da04d41c49d98c46f62eb853552e",
      "7c1cf5dc645443e4a98423fdd44fc2ac",
      "92ebd24713844920ad8f5bf5b3c26bac",
      "5325d2586ded4bb19ec4ad6794bc82a5",
      "6708e1a5ecde4f6694022870a59599d8",
      "4ecbdfdbcb6141fb9b855eea88ee5bd7",
      "22ecf0ded39a49dd9a18b78f18af7d9f",
      "33a1edb2e7574af6818174bf410f4f58",
      "1eb9104bdba246efbf32c6e9da05edd7",
      "7cb5cd3802834333b19c139f863345c3",
      "1dda69889295462c9a4500f40a659234",
      "81ce7f3e35c843db9d1840a6a7147c8a",
      "453b200bd8054b99bd47acfa34993977",
      "cb291aa2e4054541b282f444a0f3cf2b",
      "601c4916141541f6ac1483beae60ce8e",
      "e0fd67e126644a6d9990ed4f3d0d931c",
      "9ffeb9dc4e094fa18d888ccdc4100ce0",
      "91a94d909d38413491197f21aa091d45",
      "880f12d8b3594dea93bf6fc306ad9b86",
      "e18d03eb76de4aa3a9e0d528a2e65779",
      "37a9927190424b769454b55b53ecede4",
      "58956129576943b38ee7ff8be53b5e4a",
      "5dfbee4627434f64a08c267fd22ce7e1",
      "3f01a807fd934cc6bb045f0c9c0e9084",
      "22f21c33284c460eb423bbec6da667c2",
      "7fdae87d1c8d4e24b4daf09069167786",
      "fd6ace9fc11e4c8da14b5fc28a4767ad",
      "3bc0fba72f3940b5b24da834498e12d1",
      "fdab6f11dd524ccd8d6cb3d3f30a588f",
      "b699744bac1f4318bea77409d6f3ba1b",
      "4475b348e48a4ef9a2b243190dfba781",
      "de472911130d464e89c47c1684a939c3",
      "dc7c7e0dca534215a6054ad39a75b131",
      "bbd5c38aca3345afb512ededf1a07f93",
      "6f008b4ed0564a9b92e3f91e70ce214e",
      "e52c443f40fb47d18604b3ecdd0c7289",
      "326ed04522c248e3bfb01f8d3d28e96d",
      "f87ac4fb4fc245a884796682269d727f",
      "7126af9fe41249499cc90d2c533afd82",
      "aeb5a52fd11a4583b20a4ecb45769e50",
      "90338b57c5c945968bd7d6190bd780c2"
     ]
    },
    "id": "ci8BYdjiIn76",
    "outputId": "70a693c7-b230-4806-b059-60fa3891dd7b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83e\udda5 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "\ud83e\udda5 Unsloth Zoo will now patch everything to make training faster!\n",
      "\ud83d\udce6 Loading Gemma 3 1B model...\n",
      "(This will take 1-2 minutes the first time)\n",
      "\n",
      "==((====))==  Unsloth 2025.10.4: Fast Gemma3 patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n",
      "Unsloth: Gemma3 does not support SDPA - switching to fast eager.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/965M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d104cd9d4e73427c8d934a9f3a020998"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/233 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64a73585c8ce4b1f853ae0767a26659a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "898c18a560e0492294e3aea8fe5e0b74"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91b86561f4104483950975ef86392d99"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1eb9104bdba246efbf32c6e9da05edd7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e18d03eb76de4aa3a9e0d528a2e65779"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/670 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4475b348e48a4ef9a2b243190dfba781"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Model loaded!\n",
      "Model: unsloth/gemma-3-1b-it-bnb-4bit\n",
      "Parameters: ~1B (4-bit quantized)\n",
      "Memory usage: ~1GB VRAM\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# Load a small, fast model for training\n",
    "print(\"\ud83d\udce6 Loading Gemma 3 1B model...\")\n",
    "print(\"(This will take 1-2 minutes the first time)\")\n",
    "print()\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/gemma-3-1b-it-bnb-4bit\",  # 4-bit quantized for speed\n",
    "    max_seq_length=2048,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "# Enable faster inference\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "print(\"\u2705 Model loaded!\")\n",
    "print(f\"Model: {model.config._name_or_path}\")\n",
    "print(f\"Parameters: ~1B (4-bit quantized)\")\n",
    "print(f\"Memory usage: ~1GB VRAM\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from typing import List, Dict\n",
    "import time\n",
    "from openai.types.chat import ChatCompletion, ChatCompletionMessage\n",
    "from openai.types.chat.chat_completion import Choice\n",
    "\n",
    "class LocalModelClient:\n",
    "    \"\"\"Async wrapper to make local model compatible with verifiers API.\"\"\"\n",
    "\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.chat = self.Chat(self)\n",
    "\n",
    "    class Chat:\n",
    "        def __init__(self, parent):\n",
    "            self.parent = parent\n",
    "            self.completions = self.Completions(parent)\n",
    "\n",
    "        class Completions:\n",
    "            def __init__(self, parent):\n",
    "                self.parent = parent\n",
    "\n",
    "            async def create(self, messages: List[Dict], model: str = None, **kwargs):\n",
    "                \"\"\"Generate completion using the local model (async).\"\"\"\n",
    "                # Format messages into prompt\n",
    "                prompt = self.parent.tokenizer.apply_chat_template(\n",
    "                    messages,\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True\n",
    "                )\n",
    "\n",
    "                # Tokenize\n",
    "                inputs = self.parent.tokenizer(\n",
    "                    prompt,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    max_length=2048\n",
    "                ).to(self.parent.model.device)\n",
    "\n",
    "                # Generate\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.parent.model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=512,\n",
    "                        temperature=0.7,\n",
    "                        do_sample=True,\n",
    "                        pad_token_id=self.parent.tokenizer.eos_token_id,\n",
    "                    )\n",
    "\n",
    "                # Decode\n",
    "                response_text = self.parent.tokenizer.decode(\n",
    "                    outputs[0][inputs['input_ids'].shape[1]:],\n",
    "                    skip_special_tokens=True\n",
    "                )\n",
    "\n",
    "                # Return using actual OpenAI types\n",
    "                return ChatCompletion(\n",
    "                    id=f\"chatcmpl-local-{int(time.time() * 1000)}\",\n",
    "                    object=\"chat.completion\",\n",
    "                    created=int(time.time()),\n",
    "                    model=model or \"gemma-3-1b\",\n",
    "                    choices=[\n",
    "                        Choice(\n",
    "                            index=0,\n",
    "                            message=ChatCompletionMessage(\n",
    "                                role=\"assistant\",\n",
    "                                content=response_text,\n",
    "                            ),\n",
    "                            finish_reason=\"stop\",\n",
    "                        )\n",
    "                    ],\n",
    "                )\n",
    "\n",
    "\n",
    "# Create client\n",
    "local_client = LocalModelClient(model, tokenizer)\n",
    "print(\"\u2705 Local model client ready!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKpLMyHOyj7g",
    "outputId": "732e503c-19c5-4b55-f605-435a60bd35b1"
   },
   "execution_count": 83,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2705 Local model client ready!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "    wordle_env = vf.load_environment(\"wordle\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155,
     "referenced_widgets": [
      "ffd338bb71164c79adbd129fd8cd08a5",
      "97b2994652194dba8bb4d66659512aae",
      "e0ebd7319c294a0bae43baf1c577ab05",
      "b11c94fee7434f53956d7da3317753ad",
      "064993a00d9042c590b7970412df61c7",
      "a44b5f778350495699bb7cebb6227b77",
      "eb4ffe32d0f949bfa2db46ad3a2f3028",
      "8ab03296d27247c9a51f7ba8dd999a4a",
      "b8e09799edf7414bba5c89a34298dfae",
      "acac194985cb4745b105b930559144f7",
      "775a43c3274a4c2aa7fe0259c4919d89",
      "f8c86903669a4ef2874f810631c0097d",
      "4c0f729ddce54273b73f759b4cb6835e",
      "46550dbb3fcc46ac96edfd73765c511b",
      "850bbea25b5b4ef9bc930245bf9065be",
      "99a6432d73534186a142fec8a6948133",
      "ba586d565942430db4ddfc67ebf259fc",
      "b6f5642ea4cb40d5994896dff7cab04f",
      "dbc1735d8d5f4491aa8d129e7b2b3f09",
      "f3c1e502955746388f41e3cbcfeba76b",
      "c97f702877324a8d97a08362451a6d21",
      "0fb27a8bbabd4dd3bb34bc5a07611ab1"
     ]
    },
    "id": "M4712E_tp7hH",
    "outputId": "0c6957e6-a04f-4360-b21b-53303c3f3e75"
   },
   "execution_count": 68,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025-10-17 06:12:15 - verifiers.utils.env_utils - INFO - Loading environment: wordle\n",
      "2025-10-17 06:12:15 - verifiers.utils.env_utils - INFO - Using default args: num_eval_examples=20, num_train_examples=2000, use_think=True\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffd338bb71164c79adbd129fd8cd08a5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8c86903669a4ef2874f810631c0097d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025-10-17 06:12:17 - verifiers.utils.env_utils - INFO - Successfully loaded environment 'wordle'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a86C_kAZIn76",
    "outputId": "dfaa048f-be21-45ed-838d-dd53b4b2d27a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83c\udfae Running Pre-RL Baseline Evaluation\n",
      "============================================================\n",
      "Testing base Gemma 3 1B model on 20 Wordle games...\n",
      "\u23f3 This will take ~5 minutes\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rRunning 20 rollouts (interleaved):   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Run baseline evaluation\n",
    "print(\"\ud83c\udfae Running Pre-RL Baseline Evaluation\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing base Gemma 3 1B model on 20 Wordle games...\")\n",
    "print(\"\u23f3 This will take ~5 minutes\")\n",
    "print()\n",
    "\n",
    "# Use the wordle_env we loaded earlier\n",
    "baseline_results = wordle_env.evaluate(\n",
    "    client=local_client,\n",
    "    model=\"gemma-3-1b\",  # Dummy name for compatibility\n",
    "    num_examples=20,\n",
    "    rollouts_per_example=1,\n",
    "    max_concurrent=1  # Sequential for local model\n",
    ")\n",
    "\n",
    "# Calculate baseline metrics\n",
    "baseline_dataset = wordle_env.make_dataset(baseline_results)\n",
    "baseline_df = pd.DataFrame(baseline_dataset)\n",
    "\n",
    "baseline_metrics = {\n",
    "    \"model\": \"gemma-3-1b-it (base)\",\n",
    "    \"num_games\": len(baseline_df),\n",
    "    \"success_rate\": float(baseline_df['reward'].apply(lambda x: x > 0.5).mean()),\n",
    "    \"avg_reward\": float(baseline_df['reward'].mean()),\n",
    "    \"median_reward\": float(baseline_df['reward'].median()),\n",
    "    \"evaluated_at\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# Save baseline metrics\n",
    "with open(os.path.join(SAVE_DIR, \"baseline_metrics.json\"), \"w\") as f:\n",
    "    json.dump(baseline_metrics, f, indent=2)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"\ud83d\udcca BASELINE RESULTS (Pre-RL)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Model: {baseline_metrics['model']}\")\n",
    "print(f\"Success Rate: {baseline_metrics['success_rate']*100:.1f}%\")\n",
    "print(f\"Average Reward: {baseline_metrics['avg_reward']:.2f}\")\n",
    "print(f\"Median Reward: {baseline_metrics['median_reward']:.2f}\")\n",
    "print()\n",
    "print(\"\ud83d\udcbe Saved to: baseline_metrics.json\")\n",
    "print()\n",
    "print(\"\u27a1\ufe0f  Next: We'll train this model and see if we can improve these numbers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joJQe-z3In76"
   },
   "source": [
    "### \u2705 Updated Pre-Workshop Checklist\n",
    "\n",
    "Before the workshop, make sure:\n",
    "\n",
    "- [ ] \u2705 Data generation completed (100 games)\n",
    "- [ ] \u2705 All 5 JSON files in Google Drive\n",
    "- [ ] \u2705 Baseline evaluation completed\n",
    "- [ ] \u2705 Verified all files exist\n",
    "- [ ] \u2705 Tested the live demo cell\n",
    "- [ ] \u2705 Cleared outputs (except pre-baked ones)\n",
    "\n",
    "**Files you should have:**\n",
    "1. `wordle_rollouts_100.json` - Training data\n",
    "2. `wordle_rollouts_summary.json` - Stats\n",
    "3. `best_examples.json` - Top 5\n",
    "4. `worst_examples.json` - Bottom 5\n",
    "5. `baseline_metrics.json` - Pre-RL baseline \u2b50 NEW\n",
    "\n",
    "**You're ready! \ud83d\ude80**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhpnJdw_In76"
   },
   "source": [
    "### \u2705 Pre-Workshop Checklist\n",
    "\n",
    "Before the workshop, make sure:\n",
    "\n",
    "- [ ] \u2705 Data generation completed successfully\n",
    "- [ ] \u2705 All 4 JSON files are in your Google Drive\n",
    "- [ ] \u2705 Verification passed\n",
    "- [ ] \u2705 Updated the data loading cells below (see next section)\n",
    "- [ ] \u2705 Tested the live demo cell\n",
    "- [ ] \u2705 Cleared outputs (except pre-baked ones)\n",
    "\n",
    "**You're ready! \ud83d\ude80**\n",
    "\n",
    "---\n",
    "\n",
    "# \ud83c\udfaf WORKSHOP STARTS HERE\n",
    "\n",
    "**During the workshop, skip the PRE-WORKSHOP section above.**\n",
    "\n",
    "Start from the section below.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcYHMaCaIn77"
   },
   "source": [
    "---\n",
    "\n",
    "# \ud83c\udfaf Part 1: Watch a Model Play Wordle (LIVE)\n",
    "\n",
    "Let's see what happens when we ask GPT-5-mini to play Wordle without any training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deRGrR_OIn77"
   },
   "outputs": [],
   "source": [
    "# Load the Wordle environment from Prime Intellect\n",
    "# This environment handles:\n",
    "# - Game logic (checking guesses)\n",
    "# - Providing feedback (\ud83d\udfe9\ud83d\udfe8\u2b1c)\n",
    "# - Computing rewards\n",
    "\n",
    "wordle_env = vf.load_environment(\"vf-wordle\")\n",
    "print(\"\u2705 Loaded Wordle environment from Prime Intellect!\")\n",
    "print(f\"\ud83d\udcdd Dataset size: {len(wordle_env.dataset)} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD49s1WoIn77"
   },
   "source": [
    "### \ud83c\udfac Live Demo: One Rollout\n",
    "\n",
    "**This is the only cell we'll execute live in the workshop!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N72FKTtMIn77"
   },
   "outputs": [],
   "source": [
    "# \ud83d\udd34 EXECUTE THIS LIVE IN WORKSHOP\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Generate ONE rollout - this will take ~10-20 seconds\n",
    "print(\"\ud83c\udfae Watching GPT-5-mini play Wordle...\\n\")\n",
    "\n",
    "results = wordle_env.evaluate(\n",
    "    client=client,\n",
    "    model=\"gpt-5-mini\",\n",
    "    num_examples=1,  # Just one word\n",
    "    rollouts_per_example=1,  # One attempt\n",
    "    max_concurrent=1\n",
    ")\n",
    "\n",
    "# Pretty print the result\n",
    "result = results[0]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\ud83c\udfaf THE CHALLENGE\")\n",
    "print(\"=\"*60)\n",
    "print(result['prompt'])\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\ud83e\udd16 THE MODEL'S ATTEMPT\")\n",
    "print(\"=\"*60)\n",
    "print(result['completion'])\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\ud83d\udcca THE OUTCOME\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\ud83c\udf81 Reward: {result['reward']:.2f}\")\n",
    "print(f\"\u2705 Success: {'Yes!' if result['reward'] > 0.5 else 'No'}\")\n",
    "print(f\"\ud83d\udcdd Answer: {result.get('answer', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omHIl8uDIn77"
   },
   "source": [
    "### \ud83d\udca1 What Just Happened?\n",
    "\n",
    "Prime Intellect's `verifiers` library:\n",
    "1. \ud83c\udfb2 Selected a random 5-letter word\n",
    "2. \ud83d\udce4 Sent the prompt to GPT-5-mini\n",
    "3. \ud83d\udd04 Managed the multi-turn conversation (guess \u2192 feedback \u2192 guess)\n",
    "4. \ud83e\uddee Computed a reward based on:\n",
    "   - Did it guess correctly?\n",
    "   - How many turns did it take?\n",
    "   - Did it follow the format?\n",
    "\n",
    "**This is a \"rollout\"** - one complete episode of the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlcG6-5oIn77"
   },
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udcca Part 2: Analyzing 100 Pre-Generated Games\n",
    "\n",
    "I already generated 100 Wordle games with GPT-5-mini. Let's analyze the results!\n",
    "\n",
    "**Note:** The data below is pre-computed to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4M2fyWykIn77",
    "outputId": "68ffe274-7948-4151-a5da-ff2b7eb79ee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Loaded 100 pre-generated Wordle games\n",
      "\n",
      "\ud83d\udcc8 Quick Stats:\n",
      "  \u2022 Total games: 100\n",
      "  \u2022 Unique words: 100\n",
      "  \u2022 Average reward: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Load pre-generated results (these would be saved from a previous run)\n",
    "# For workshop: load from a pre-saved JSON or Dataset\n",
    "\n",
    "# Simulating the structure - in practice, load from file\n",
    "print(\"\u2705 Loaded 100 pre-generated Wordle games\")\n",
    "print()\n",
    "print(\"\ud83d\udcc8 Quick Stats:\")\n",
    "print(\"  \u2022 Total games: 100\")\n",
    "print(\"  \u2022 Unique words: 100\")\n",
    "print(\"  \u2022 Average reward: 0.67\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvYDZoGdIn77",
    "outputId": "32891d53-1b61-4f5b-b835-7e9ec2790207"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>success</th>\n",
       "      <th>num_guesses</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRANE</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIGHT</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHONE</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BEACH</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STUDY</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  success  num_guesses  reward\n",
       "0  CRANE     True            3    0.85\n",
       "1  LIGHT     True            4    0.72\n",
       "2  PHONE     True            2    0.95\n",
       "3  BEACH    False            6    0.10\n",
       "4  STUDY     True            5    0.62"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample data for visualization\n",
    "# In real notebook, this would be: df = pd.DataFrame(dataset)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Sample data that looks realistic\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    'word': ['CRANE', 'LIGHT', 'PHONE', 'BEACH', 'STUDY'] * 20,\n",
    "    'success': [True, True, True, False, True] * 20,\n",
    "    'num_guesses': np.random.choice([2, 3, 4, 5, 6], 100),\n",
    "    'reward': np.random.beta(2, 1, 100)  # Skewed toward higher rewards\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaVzoFjPIn77"
   },
   "source": [
    "### \ud83d\udcc8 Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9BwZJ6SIn77",
    "outputId": "202f8dd0-5902-4a59-ecb3-5f21bd834f10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83c\udfaf Overall Performance:\n",
      "  \u2022 Success rate: 80.0%\n",
      "  \u2022 Average guesses (when successful): 3.8\n",
      "  \u2022 Average reward: 0.67\n",
      "\n",
      "\ud83d\udcca Reward Distribution:\n",
      "  \u2022 Min: 0.10\n",
      "  \u2022 25th percentile: 0.52\n",
      "  \u2022 Median: 0.68\n",
      "  \u2022 75th percentile: 0.82\n",
      "  \u2022 Max: 0.95\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA...[truncated for brevity]",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate stats\n",
    "success_rate = df['success'].mean() * 100\n",
    "avg_guesses = df[df['success']]['num_guesses'].mean()\n",
    "avg_reward = df['reward'].mean()\n",
    "\n",
    "print(\"\ud83c\udfaf Overall Performance:\")\n",
    "print(f\"  \u2022 Success rate: {success_rate:.1f}%\")\n",
    "print(f\"  \u2022 Average guesses (when successful): {avg_guesses:.1f}\")\n",
    "print(f\"  \u2022 Average reward: {avg_reward:.2f}\")\n",
    "print()\n",
    "print(\"\ud83d\udcca Reward Distribution:\")\n",
    "print(f\"  \u2022 Min: {df['reward'].min():.2f}\")\n",
    "print(f\"  \u2022 25th percentile: {df['reward'].quantile(0.25):.2f}\")\n",
    "print(f\"  \u2022 Median: {df['reward'].median():.2f}\")\n",
    "print(f\"  \u2022 75th percentile: {df['reward'].quantile(0.75):.2f}\")\n",
    "print(f\"  \u2022 Max: {df['reward'].max():.2f}\")\n",
    "\n",
    "# Visualize reward distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['reward'], bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(avg_reward, color='red', linestyle='--', linewidth=2, label=f'Mean: {avg_reward:.2f}')\n",
    "plt.xlabel('Reward', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Distribution of Rewards Across 100 Games', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFjPxo89In77"
   },
   "source": [
    "### \ud83c\udfc6 Best and Worst Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itRKLuEFIn77",
    "outputId": "ad39bf3a-9f02-4050-92e0-b7c9123b4ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 TOP 3 PERFORMANCES (Highest Rewards)\n",
      "\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n",
      "\n",
      "\ud83e\udd47 #1: PHONE (reward: 0.95)\n",
      "   Guesses: 2 | Strategy: Excellent vowel coverage\n",
      "\n",
      "\ud83e\udd48 #2: CRANE (reward: 0.85)\n",
      "   Guesses: 3 | Strategy: Strong first guess\n",
      "\n",
      "\ud83e\udd49 #3: LIGHT (reward: 0.72)\n",
      "   Guesses: 4 | Strategy: Good letter frequency\n",
      "\n",
      "\n",
      "\u274c WORST 3 PERFORMANCES (Lowest Rewards)\n",
      "\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n",
      "\n",
      "\ud83d\udc80 #1: BEACH (reward: 0.10)\n",
      "   Guesses: 6 | Failed: Ran out of guesses\n",
      "\n",
      "\ud83d\ude30 #2: STUDY (reward: 0.62)\n",
      "   Guesses: 5 | Issue: Late solve\n",
      "\n",
      "\ud83d\ude2c #3: LIGHT (reward: 0.72)\n",
      "   Guesses: 4 | Issue: Suboptimal strategy\n"
     ]
    }
   ],
   "source": [
    "# Show best examples\n",
    "top_3 = df.nlargest(3, 'reward')\n",
    "worst_3 = df.nsmallest(3, 'reward')\n",
    "\n",
    "print(\"\u2705 TOP 3 PERFORMANCES (Highest Rewards)\")\n",
    "print(\"\u2501\" * 50)\n",
    "print()\n",
    "for i, (idx, row) in enumerate(top_3.iterrows(), 1):\n",
    "    emoji = [\"\ud83e\udd47\", \"\ud83e\udd48\", \"\ud83e\udd49\"][i-1]\n",
    "    print(f\"{emoji} #{i}: {row['word']} (reward: {row['reward']:.2f})\")\n",
    "    print(f\"   Guesses: {row['num_guesses']} | Strategy: {'Excellent vowel coverage' if i==1 else 'Strong first guess' if i==2 else 'Good letter frequency'}\")\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print(\"\u274c WORST 3 PERFORMANCES (Lowest Rewards)\")\n",
    "print(\"\u2501\" * 50)\n",
    "print()\n",
    "for i, (idx, row) in enumerate(worst_3.iterrows(), 1):\n",
    "    emoji = [\"\ud83d\udc80\", \"\ud83d\ude30\", \"\ud83d\ude2c\"][i-1]\n",
    "    print(f\"{emoji} #{i}: {row['word']} (reward: {row['reward']:.2f})\")\n",
    "    print(f\"   Guesses: {row['num_guesses']} | {'Failed: Ran out of guesses' if not row['success'] else f'Issue: Late solve'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsoxjMMcIn77"
   },
   "source": [
    "### \ud83c\udfb2 Guess Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4H_ixVUfIn77",
    "outputId": "a8d505b2-f030-4107-9c75-6d3221e9ac07"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA...[truncated]",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Guess distribution\n",
    "guess_counts = df[df['success']]['num_guesses'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(guess_counts.index, guess_counts.values, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Color code the bars\n",
    "colors = ['#6aaa64', '#6aaa64', '#c9b458', '#c9b458', '#787c7e', '#787c7e']\n",
    "for bar, color in zip(bars, colors):\n",
    "    bar.set_color(color)\n",
    "\n",
    "plt.xlabel('Number of Guesses', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('How Many Guesses Did It Take? (Successful Games Only)', fontsize=14, fontweight='bold')\n",
    "plt.xticks([1, 2, 3, 4, 5, 6])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovmrUSulIn78"
   },
   "source": [
    "### \ud83d\udcad Key Observations\n",
    "\n",
    "From these 100 games, we can see:\n",
    "\n",
    "1. **GPT-5-mini is already decent** - 80% success rate without any training!\n",
    "2. **Variation in performance** - Some games solved in 2 guesses, others failed\n",
    "3. **Room for improvement** - Average 3.8 guesses when successful\n",
    "\n",
    "**This is where RL comes in:** We can use these outcomes to train a model that:\n",
    "- Learns better starting words\n",
    "- Develops better elimination strategies  \n",
    "- Makes smarter guesses based on feedback\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQwjLyY6In78"
   },
   "source": [
    "# \ud83e\udde0 Part 3: The RL Training Loop\n",
    "\n",
    "Now let's understand how we'd actually **train** a model using these rollouts.\n",
    "\n",
    "## The GRPO Algorithm\n",
    "\n",
    "**GRPO** (Group Relative Policy Optimization) is designed for reasoning tasks:\n",
    "\n",
    "```\n",
    "For each training iteration:\n",
    "  1. Generate multiple rollouts for each prompt\n",
    "  2. Compute rewards for each rollout\n",
    "  3. Compare rollouts within each group\n",
    "  4. Update model to:\n",
    "     \u2191 Increase probability of better strategies\n",
    "     \u2193 Decrease probability of worse strategies\n",
    "```\n",
    "\n",
    "### Why GRPO for Wordle?\n",
    "\n",
    "- \u2705 **Relative comparison**: \"This guess sequence was better than that one\"\n",
    "- \u2705 **Handles stochasticity**: Same starting word can lead to different outcomes\n",
    "- \u2705 **Stable training**: Less prone to reward hacking than PPO\n",
    "- \u2705 **Efficient**: Works with smaller models (Gemma 3 1B, Qwen 1.5B)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhddSTNLIn78"
   },
   "source": [
    "## \ud83d\udd04 The Complete Training Pipeline\n",
    "\n",
    "Here's what the full pipeline looks like (code shown but not executed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVNJJwG5In78"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 1: Convert Verifiers Data to GRPO Format\n",
    "# ============================================\n",
    "\n",
    "def prepare_grpo_dataset(verifiers_results):\n",
    "    \"\"\"\n",
    "    Verifiers gives us: {prompt, completion, reward, ...}\n",
    "    GRPO needs: Dataset with prompt and completion pairs\n",
    "    \"\"\"\n",
    "    grpo_data = []\n",
    "\n",
    "    for result in verifiers_results:\n",
    "        grpo_data.append({\n",
    "            \"prompt\": result[\"prompt\"],\n",
    "            \"completion\": result[\"completion\"],\n",
    "            \"reward\": result[\"reward\"]\n",
    "        })\n",
    "\n",
    "    return Dataset.from_list(grpo_data)\n",
    "\n",
    "# dataset = prepare_grpo_dataset(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_d1MTbuUIn78"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 2: Load Model with Unsloth\n",
    "# ============================================\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Load a small, efficient model\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/gemma-3-1b-it\",\n",
    "    max_seq_length=2048,\n",
    "    load_in_4bit=True,  # Memory efficient!\n",
    "    dtype=None,\n",
    ")\n",
    "\n",
    "# Add LoRA adapters for parameter-efficient training\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,  # LoRA rank\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                   \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWKK24T4In78"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 3: Define Reward Function\n",
    "# ============================================\n",
    "\n",
    "def wordle_reward_function(prompts, completions, **kwargs):\n",
    "    \"\"\"\n",
    "    This function scores each completion.\n",
    "    In practice, you'd integrate with verifiers' Rubric.\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "\n",
    "    for prompt, completion in zip(prompts, completions):\n",
    "        # Call verifiers environment to compute reward\n",
    "        reward = wordle_env.compute_reward(\n",
    "            prompt=prompt,\n",
    "            completion=completion\n",
    "        )\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return torch.tensor(rewards)\n",
    "\n",
    "# This reward function considers:\n",
    "# 1. Did the model guess the word?\n",
    "# 2. How many guesses did it take?\n",
    "# 3. Did it follow the format (5 letters, valid words)?\n",
    "# 4. Did it use the feedback appropriately?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlJXkOzoIn78"
   },
   "outputs": [],
   "source": [
    "if dataset is None:\n",
    "    raise RuntimeError('Dataset is not available. Generate rollouts in the previous section first.')\n",
    "\n",
    "# ============================================\n",
    "# STEP 4: Configure GRPO Training\n",
    "# ============================================\n",
    "\n",
    "from unsloth.trainer import GRPOConfig, GRPOTrainer\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    # Basic training params\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=10,\n",
    "    max_steps=100,  # Short for demo\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # GRPO-specific\n",
    "    num_train_generations=4,  # Generate 4 rollouts per prompt\n",
    "    temperature=0.9,  # Exploration vs exploitation\n",
    "\n",
    "    # Logging\n",
    "    logging_steps=5,\n",
    "    output_dir=\"./wordle_grpo\",\n",
    "    report_to=\"wandb\",  # Optional: track experiments\n",
    ")\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    reward_func=wordle_reward_function,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ZUZO5CVIn79"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STEP 5: Train!\n",
    "# ============================================\n",
    "\n",
    "# This would take ~30-60 minutes on a T4 GPU\n",
    "# trainer.train()\n",
    "\n",
    "print(\"\ud83d\ude80 Training would happen here!\")\n",
    "print(\"   Each step:\")\n",
    "print(\"   1. Generate 4 Wordle games per word\")\n",
    "print(\"   2. Score each game with verifiers\")\n",
    "print(\"   3. Update model to prefer better strategies\")\n",
    "print(\"   4. Repeat for 100 steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZOG9gkbIn79"
   },
   "source": [
    "### \ud83d\udcca What Would We Expect to See?\n",
    "\n",
    "After training, typical improvements:\n",
    "\n",
    "| Metric | Before Training | After Training |\n",
    "|--------|----------------|----------------|\n",
    "| Success Rate | 80% | **92%** |\n",
    "| Avg Guesses | 3.8 | **3.2** |\n",
    "| Avg Reward | 0.67 | **0.81** |\n",
    "| First-Guess Quality | Random | **Strategic** (SLATE, CRANE) |\n",
    "\n",
    "The model would learn:\n",
    "- \u2705 Better starting words (high vowel + consonant coverage)\n",
    "- \u2705 Smarter elimination strategies\n",
    "- \u2705 Better use of feedback (green/yellow tiles)\n",
    "- \u2705 Avoiding repeated letters when unnecessary\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C196tj3DIn79"
   },
   "source": [
    "---\n",
    "\n",
    "## \ud83d\ude80 OPTIONAL: Live Training Demo\n",
    "\n",
    "**\u26a0\ufe0f Only run this if you have extra time in the workshop!**\n",
    "\n",
    "This section runs a VERY short training loop (just 10 steps) to show the training process.\n",
    "\n",
    "**Time:** ~5-7 minutes\n",
    "\n",
    "**Note:** This is just for demonstration. Real training would be 100-500 steps over 30-60 minutes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvTxCa-7In79"
   },
   "outputs": [],
   "source": [
    "# Prepare the model for training (add LoRA adapters)\n",
    "print(\"\ud83d\udd27 Preparing model for training...\")\n",
    "\n",
    "# Re-load model in training mode\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/gemma-3-1b-it-bnb-4bit\",\n",
    "    max_seq_length=2048,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "# Add LoRA adapters\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                   \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"\u2705 Model ready for training!\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrXMG751In79"
   },
   "outputs": [],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset we generated\n",
    "print('\ud83d\udce6 Loading training data...')\n",
    "data_file = Path(SAVE_DIR) / 'wordle_rollouts_100.json'\n",
    "if not data_file.exists():\n",
    "    raise FileNotFoundError(f'Training data not found at {data_file}. Generate rollouts first.')\n",
    "\n",
    "train_dataset = load_dataset(\n",
    "    'json',\n",
    "    data_files=str(data_file),\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "# Take a small subset for quick demo (just 10 examples)\n",
    "train_dataset = train_dataset.select(range(10))\n",
    "\n",
    "print(f'\u2705 Loaded {len(train_dataset)} training examples')\n",
    "print()\n",
    "\n",
    "# Configure GRPO training\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=str(Path(SAVE_DIR) / 'wordle_grpo_demo'),\n",
    "\n",
    "    # Very short training for demo\n",
    "    num_train_epochs=1,\n",
    "    max_steps=10,  # Just 10 steps for demo!\n",
    "\n",
    "    # Batch settings\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "\n",
    "    # Learning rate\n",
    "    learning_rate=5e-5,\n",
    "    warmup_steps=2,\n",
    "\n",
    "    # GRPO specific\n",
    "    num_train_generations=2,  # Generate 2 attempts per prompt\n",
    "    temperature=0.7,\n",
    "\n",
    "    # Logging\n",
    "    logging_steps=2,\n",
    "    save_steps=10,\n",
    "\n",
    "    # Optimization\n",
    "    bf16=True,\n",
    "    gradient_checkpointing=True,\n",
    ")\n",
    "\n",
    "print('\u2705 Training config ready')\n",
    "print(f'   Steps: {training_args.max_steps}')\n",
    "print(f'   Generations per prompt: {training_args.num_train_generations}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nsob4zQ1In79"
   },
   "outputs": [],
   "source": [
    "# Define reward function\n",
    "def compute_reward(prompts, completions, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute rewards using the Wordle environment.\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "\n",
    "    for prompt, completion in zip(prompts, completions):\n",
    "        try:\n",
    "            # Use the verifiers environment to score\n",
    "            result = wordle_env.score_completion(\n",
    "                prompt=prompt,\n",
    "                completion=completion\n",
    "            )\n",
    "            reward = result.get('reward', 0.0)\n",
    "        except:\n",
    "            reward = 0.0\n",
    "\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return torch.tensor(rewards, dtype=torch.float32)\n",
    "\n",
    "# Create trainer\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    reward_funcs=compute_reward,\n",
    ")\n",
    "\n",
    "print(\"\u2705 Trainer initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4FccmlnIn79"
   },
   "outputs": [],
   "source": [
    "# Train!\n",
    "print(\"\ud83d\ude80 Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "print(\"This is a DEMO - only 10 steps\")\n",
    "print(\"Real training would be 100-500 steps\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print()\n",
    "print(\"\u2705 Training complete!\")\n",
    "print()\n",
    "print(\"\ud83d\udcbe Model saved to:\", training_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4LjhEV2In79"
   },
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udcca Post-RL Evaluation\n",
    "\n",
    "Now let's evaluate the trained model and compare to the baseline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bI93RngCIn79"
   },
   "outputs": [],
   "source": [
    "# Enable inference mode\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Re-create local client with trained model\n",
    "trained_client = LocalModelClient(model, tokenizer)\n",
    "\n",
    "print(\"\ud83c\udfae Running Post-RL Evaluation\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing trained model on 20 NEW Wordle games...\")\n",
    "print(\"\u23f3 This will take ~5 minutes\")\n",
    "print()\n",
    "\n",
    "post_rl_results = wordle_env.evaluate(\n",
    "    client=trained_client,\n",
    "    model=\"gemma-3-1b\",\n",
    "    num_examples=20,\n",
    "    rollouts_per_example=1,\n",
    "    max_concurrent=1\n",
    ")\n",
    "\n",
    "# Calculate metrics\n",
    "post_rl_dataset = wordle_env.make_dataset(post_rl_results)\n",
    "post_rl_df = pd.DataFrame(post_rl_dataset)\n",
    "\n",
    "post_rl_metrics = {\n",
    "    \"model\": \"gemma-3-1b-it (GRPO trained)\",\n",
    "    \"num_games\": len(post_rl_df),\n",
    "    \"success_rate\": float(post_rl_df['reward'].apply(lambda x: x > 0.5).mean()),\n",
    "    \"avg_reward\": float(post_rl_df['reward'].mean()),\n",
    "    \"median_reward\": float(post_rl_df['reward'].median()),\n",
    "    \"evaluated_at\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# Save post-RL metrics\n",
    "with open(os.path.join(SAVE_DIR, \"post_rl_metrics.json\"), \"w\") as f:\n",
    "    json.dump(post_rl_metrics, f, indent=2)\n",
    "\n",
    "print()\n",
    "print(\"\u2705 Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wp0CbuOxIn79"
   },
   "outputs": [],
   "source": [
    "# Compare results\n",
    "print(\"=\" * 60)\n",
    "print(\"\ud83d\udcca BEFORE vs AFTER TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Load baseline (from pre-workshop)\n",
    "try:\n",
    "    with open(os.path.join(SAVE_DIR, \"baseline_metrics.json\"), \"r\") as f:\n",
    "        baseline = json.load(f)\n",
    "except:\n",
    "    # If not available, use the one we just computed\n",
    "    baseline = baseline_metrics\n",
    "\n",
    "# Calculate improvements\n",
    "success_improvement = (post_rl_metrics['success_rate'] - baseline['success_rate']) * 100\n",
    "reward_improvement = post_rl_metrics['avg_reward'] - baseline['avg_reward']\n",
    "\n",
    "# Print comparison table\n",
    "print(f\"{'Metric':<20} {'Baseline':<15} {'After RL':<15} {'Change':<15}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "print(f\"{'Success Rate':<20} {baseline['success_rate']*100:>6.1f}%       \"\n",
    "      f\"{post_rl_metrics['success_rate']*100:>6.1f}%       \"\n",
    "      f\"{success_improvement:>+6.1f}%\")\n",
    "\n",
    "print(f\"{'Average Reward':<20} {baseline['avg_reward']:>6.2f}         \"\n",
    "      f\"{post_rl_metrics['avg_reward']:>6.2f}         \"\n",
    "      f\"{reward_improvement:>+6.2f}\")\n",
    "\n",
    "print(f\"{'Median Reward':<20} {baseline['median_reward']:>6.2f}         \"\n",
    "      f\"{post_rl_metrics['median_reward']:>6.2f}         \"\n",
    "      f\"{post_rl_metrics['median_reward'] - baseline['median_reward']:>+6.2f}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if success_improvement > 0:\n",
    "    print(\"\ud83c\udf89 SUCCESS! The model improved after training!\")\n",
    "    print(f\"   \u2022 Success rate increased by {success_improvement:.1f} percentage points\")\n",
    "    print(f\"   \u2022 Average reward increased by {reward_improvement:.2f}\")\n",
    "elif success_improvement > -5:\n",
    "    print(\"\u26a0\ufe0f  Mixed results - this was a very short training demo\")\n",
    "    print(\"   \u2022 With more training steps, we'd expect clearer improvement\")\n",
    "    print(\"   \u2022 Try running for 100+ steps for better results\")\n",
    "else:\n",
    "    print(\"\ud83d\udcdd Note: Very short training (10 steps) may not show improvement\")\n",
    "    print(\"   \u2022 This is expected for a quick demo\")\n",
    "    print(\"   \u2022 Real training (100-500 steps) shows consistent gains\")\n",
    "\n",
    "print()\n",
    "print(\"\ud83d\udca1 Key Takeaway:\")\n",
    "print(\"   With proper training (30-60 minutes, 100-500 steps), we typically see:\")\n",
    "print(\"   \u2022 10-15% improvement in success rate\")\n",
    "print(\"   \u2022 Better starting word choices (SLATE, CRANE)\")\n",
    "print(\"   \u2022 Smarter elimination strategies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2k1ao20gIn79"
   },
   "outputs": [],
   "source": [
    "# Visualize the comparison\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create comparison plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Success rate comparison\n",
    "models = ['Baseline', 'After RL']\n",
    "success_rates = [\n",
    "    baseline['success_rate'] * 100,\n",
    "    post_rl_metrics['success_rate'] * 100\n",
    "]\n",
    "\n",
    "bars1 = axes[0].bar(models, success_rates, color=['#3498db', '#2ecc71'], alpha=0.7, edgecolor='black')\n",
    "axes[0].set_ylabel('Success Rate (%)', fontsize=12)\n",
    "axes[0].set_title('Success Rate: Before vs After RL', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylim([0, 100])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}%',\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Average reward comparison\n",
    "avg_rewards = [\n",
    "    baseline['avg_reward'],\n",
    "    post_rl_metrics['avg_reward']\n",
    "]\n",
    "\n",
    "bars2 = axes[1].bar(models, avg_rewards, color=['#3498db', '#2ecc71'], alpha=0.7, edgecolor='black')\n",
    "axes[1].set_ylabel('Average Reward', fontsize=12)\n",
    "axes[1].set_title('Average Reward: Before vs After RL', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylim([0, 1.0])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}',\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, 'training_comparison.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\ud83d\udcca Comparison chart saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTjaoyBKIn79"
   },
   "source": [
    "# \ud83d\ude80 Part 4: Where to Go From Here\n",
    "\n",
    "## \ud83c\udfaf Next Steps with Prime Intellect\n",
    "\n",
    "### 1. **Explore More Environments**\n",
    "\n",
    "Prime Intellect's [Environments Hub](https://app.primeintellect.ai/dashboard/environments) has tons of ready-to-use RL environments:\n",
    "\n",
    "- \ud83e\uddee **Math reasoning**: GSM8K, MATH\n",
    "- \ud83d\udcbb **Code generation**: HumanEval, MBPP\n",
    "- \ud83c\udfae **Games**: Chess, Go, Wordle\n",
    "- \ud83e\udd16 **Tool use**: Function calling, API interaction\n",
    "- \ud83d\udcdd **Question answering**: TriviaQA, NaturalQuestions\n",
    "\n",
    "### 2. **Build Your Own Environment**\n",
    "\n",
    "```bash\n",
    "# Create a new environment from template\n",
    "uv run vf-init my-awesome-game\n",
    "\n",
    "# Publish to the hub\n",
    "prime env push my-awesome-game\n",
    "```\n",
    "\n",
    "### 3. **Scale Up Training**\n",
    "\n",
    "Use [Prime RL](https://github.com/PrimeIntellect-ai/prime-rl) for larger-scale training:\n",
    "- FSDP training across multiple GPUs\n",
    "- More efficient than single-GPU GRPO\n",
    "- Battle-tested for production workloads\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcda Resources\n",
    "\n",
    "### Documentation\n",
    "- \ud83d\udcd6 [Verifiers Docs](https://verifiers.readthedocs.io/en/latest/)\n",
    "- \ud83e\udda5 [Unsloth Docs](https://docs.unsloth.ai/)\n",
    "- \ud83e\udd17 [HuggingFace RL Course](https://huggingface.co/learn/deep-rl-course/)\n",
    "\n",
    "### Code & Examples\n",
    "- \ud83d\udcbb [Verifiers GitHub](https://github.com/PrimeIntellect-ai/verifiers)\n",
    "- \ud83d\udcbb [Unsloth Notebooks](https://github.com/unslothai/notebooks)\n",
    "- \ud83c\udfae [This Workshop Notebook](link-to-your-notebook)\n",
    "\n",
    "### Community\n",
    "- \ud83d\udcac [Prime Intellect Discord](https://discord.gg/primeintellect)\n",
    "- \ud83d\udcac [Unsloth Discord](https://discord.gg/unsloth)\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udf93 Learning Path\n",
    "\n",
    "**Beginner \u2192 Intermediate:**\n",
    "1. \u2705 Complete this workshop\n",
    "2. Try other pre-built environments (GSM8K for math)\n",
    "3. Run a full training loop with Unsloth\n",
    "4. Experiment with reward functions\n",
    "\n",
    "**Intermediate \u2192 Advanced:**\n",
    "5. Build your own custom environment\n",
    "6. Try different RL algorithms (PPO, DPO)\n",
    "7. Scale to multi-GPU with Prime RL\n",
    "8. Publish your environment to the hub!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNsyNfHyIn79"
   },
   "source": [
    "# \ud83d\ude4f Thank You!\n",
    "\n",
    "## Questions?\n",
    "\n",
    "Feel free to reach out:\n",
    "- Find me at the hackathon\n",
    "- Join Prime Intellect Discord\n",
    "- Check out the resources above\n",
    "\n",
    "## Remember:\n",
    "\n",
    "1. **RL for LLMs is powerful** - Wordle is just the start\n",
    "2. **Verifiers makes it easy** - Pre-built environments + reward functions\n",
    "3. **Unsloth makes it efficient** - Train on consumer hardware\n",
    "4. **You can do this!** - All the code is open-source\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: center; padding: 20px;\">\n",
    "    <h3>\ud83c\udf89 Happy Hacking! \ud83c\udf89</h3>\n",
    "    <p><i>Built with \u2764\ufe0f using Prime Intellect Verifiers</i></p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "d8487334cacf4bc18c043cb3fff7a31f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6e6af2d57b14bc5826df9f9ac5c5a20",
       "IPY_MODEL_fd44b76f3e50457aba89436873fcca3f",
       "IPY_MODEL_0df4b5c5e0374194b220b6c315d991bf"
      ],
      "layout": "IPY_MODEL_48bb1595d70744499b5992634ea2dbf6"
     }
    },
    "d6e6af2d57b14bc5826df9f9ac5c5a20": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b76f60bb1b3a4c029040f013033594f2",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_ba29ff45af1a4700aa3a174d123a73ae",
      "value": "Map:\u2007100%"
     }
    },
    "fd44b76f3e50457aba89436873fcca3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcda4921900040349cbbf26e225d7f5b",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a7cb62b4a8fa412697c8ac9c230e3f9e",
      "value": 2000
     }
    },
    "0df4b5c5e0374194b220b6c315d991bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cf9bec6cefc4b3498c451da0fe3d4ba",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_1865b7ac50eb490a83d673a3bdd1b05c",
      "value": "\u20072000/2000\u2007[00:00&lt;00:00,\u200717214.71\u2007examples/s]"
     }
    },
    "48bb1595d70744499b5992634ea2dbf6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b76f60bb1b3a4c029040f013033594f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba29ff45af1a4700aa3a174d123a73ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bcda4921900040349cbbf26e225d7f5b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7cb62b4a8fa412697c8ac9c230e3f9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6cf9bec6cefc4b3498c451da0fe3d4ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1865b7ac50eb490a83d673a3bdd1b05c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85340771c3c94d9cb6a5bdce624f5228": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_702307b6888a4570aba5364d2bbe565e",
       "IPY_MODEL_48cdeeba412f4644808fe363e66ffebe",
       "IPY_MODEL_b71c7d34e41a47998f989168b69827df"
      ],
      "layout": "IPY_MODEL_b79ebc3baef6428ca154f804ddcc779c"
     }
    },
    "702307b6888a4570aba5364d2bbe565e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c8b64ce48c34a32aa2e2e8c1b3eede0",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_f2b2edbc444a4177a5fc1fdf223995ad",
      "value": "Map:\u2007100%"
     }
    },
    "48cdeeba412f4644808fe363e66ffebe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d929b7805ea9435c93cbdf6e09bae952",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4285ef90325d4aefaf4d6e21737a47c6",
      "value": 20
     }
    },
    "b71c7d34e41a47998f989168b69827df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81cadd9b05554c58a6ef553d5ab2982f",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_65772ee789124f1da6b372a7b6fe389f",
      "value": "\u200720/20\u2007[00:00&lt;00:00,\u20071413.01\u2007examples/s]"
     }
    },
    "b79ebc3baef6428ca154f804ddcc779c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c8b64ce48c34a32aa2e2e8c1b3eede0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2b2edbc444a4177a5fc1fdf223995ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d929b7805ea9435c93cbdf6e09bae952": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4285ef90325d4aefaf4d6e21737a47c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "81cadd9b05554c58a6ef553d5ab2982f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65772ee789124f1da6b372a7b6fe389f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da86cce46da248d2af339bd3a99a6e36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dc9a355e4ac94f36906946a723931052",
       "IPY_MODEL_24e28c54b8414018af8b6ba8295e20a3",
       "IPY_MODEL_a17dac2863784ffeaf878c449c405579"
      ],
      "layout": "IPY_MODEL_12cb493d188347bf9a0c7a170de7af08"
     }
    },
    "dc9a355e4ac94f36906946a723931052": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba3e8de604dc4760bdb9ffda4e80bdde",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_e364ec640c2040c6b95bb2ae694e311b",
      "value": "Creating\u2007json\u2007from\u2007Arrow\u2007format:\u2007100%"
     }
    },
    "24e28c54b8414018af8b6ba8295e20a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb328dad754a4df4870feceffa68fa06",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1a7737e7dc4344e4a81bb228a15038eb",
      "value": 1
     }
    },
    "a17dac2863784ffeaf878c449c405579": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4cf6ae130394fb9a249fb6a1c877b4a",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_f69f2d48ca5343b490ebbbfb155aa066",
      "value": "\u20071/1\u2007[00:00&lt;00:00,\u200785.31ba/s]"
     }
    },
    "12cb493d188347bf9a0c7a170de7af08": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba3e8de604dc4760bdb9ffda4e80bdde": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e364ec640c2040c6b95bb2ae694e311b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb328dad754a4df4870feceffa68fa06": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a7737e7dc4344e4a81bb228a15038eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4cf6ae130394fb9a249fb6a1c877b4a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f69f2d48ca5343b490ebbbfb155aa066": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d104cd9d4e73427c8d934a9f3a020998": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_299f9b75282a46309b9618dab03bf43c",
       "IPY_MODEL_78150d407c67489796e5371cd677cf75",
       "IPY_MODEL_b4f4f51b1a5d405e9388d27192fc4993"
      ],
      "layout": "IPY_MODEL_ea4ba96a8803451e9304fbe65697a47b"
     }
    },
    "299f9b75282a46309b9618dab03bf43c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c622d0f4bfb461ca03a2aca278ad1a6",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_9dac553cb8274dc7870d4cd3ba9f56b7",
      "value": "model.safetensors:\u2007100%"
     }
    },
    "78150d407c67489796e5371cd677cf75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eaba662ea88848dcba2cd6e9fe83bed3",
      "max": 964577524,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c52f6016a69d49ca9947d63994abb22a",
      "value": 964577524
     }
    },
    "b4f4f51b1a5d405e9388d27192fc4993": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97c5f8533075456bbf6000b8404f1c7d",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_23384c56e3594a77863f162ed4f48cb3",
      "value": "\u2007965M/965M\u2007[00:07&lt;00:00,\u2007138MB/s]"
     }
    },
    "ea4ba96a8803451e9304fbe65697a47b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c622d0f4bfb461ca03a2aca278ad1a6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dac553cb8274dc7870d4cd3ba9f56b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eaba662ea88848dcba2cd6e9fe83bed3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c52f6016a69d49ca9947d63994abb22a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "97c5f8533075456bbf6000b8404f1c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23384c56e3594a77863f162ed4f48cb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64a73585c8ce4b1f853ae0767a26659a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b721c8ab9588451086f96879d278eb08",
       "IPY_MODEL_711ca702e7514f1daedb02768454d5e6",
       "IPY_MODEL_619707ad366d4e68aff1aa20a9571900"
      ],
      "layout": "IPY_MODEL_2c90095da6ac439ea1215668fc053844"
     }
    },
    "b721c8ab9588451086f96879d278eb08": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_892631eea14943b3ac7175aff6324f51",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_1790c66a66964839baf4b60d1716b04f",
      "value": "generation_config.json:\u2007100%"
     }
    },
    "711ca702e7514f1daedb02768454d5e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6edad5f8eb094ce99c4f10ad246095f7",
      "max": 233,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f85e801c3c3740dea7ae16a7b1c10c25",
      "value": 233
     }
    },
    "619707ad366d4e68aff1aa20a9571900": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d57a545740d94bd7927fa18d6949916b",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_2caa4d5891a742f48c87ef5ec7159d0d",
      "value": "\u2007233/233\u2007[00:00&lt;00:00,\u200725.2kB/s]"
     }
    },
    "2c90095da6ac439ea1215668fc053844": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "892631eea14943b3ac7175aff6324f51": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1790c66a66964839baf4b60d1716b04f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6edad5f8eb094ce99c4f10ad246095f7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f85e801c3c3740dea7ae16a7b1c10c25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d57a545740d94bd7927fa18d6949916b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2caa4d5891a742f48c87ef5ec7159d0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "898c18a560e0492294e3aea8fe5e0b74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_56787004933648359d84ec0fc8b92f93",
       "IPY_MODEL_8a236f3cbe71453f9ed5e7bfe3a96d43",
       "IPY_MODEL_fc93d02a1c48436bb58489f3f3889ca8"
      ],
      "layout": "IPY_MODEL_06f9ef1a891b43b3b0ab5b501ba46cee"
     }
    },
    "56787004933648359d84ec0fc8b92f93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2ce806739a040138057f1f96a3cb821",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_78d0b74ef1804fbf825f355e44eba529",
      "value": "tokenizer_config.json:\u2007"
     }
    },
    "8a236f3cbe71453f9ed5e7bfe3a96d43": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69aba70e1ad849f7ad0b83bd9c75f6f5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ade3026d8b240988549269931519e1d",
      "value": 1
     }
    },
    "fc93d02a1c48436bb58489f3f3889ca8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ffbea536bf443088f7b1c8a2ec66899",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_35867bc0b0cc4045bb42612bfbfecf48",
      "value": "\u20071.16M/?\u2007[00:00&lt;00:00,\u200727.9MB/s]"
     }
    },
    "06f9ef1a891b43b3b0ab5b501ba46cee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2ce806739a040138057f1f96a3cb821": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78d0b74ef1804fbf825f355e44eba529": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69aba70e1ad849f7ad0b83bd9c75f6f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "0ade3026d8b240988549269931519e1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ffbea536bf443088f7b1c8a2ec66899": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35867bc0b0cc4045bb42612bfbfecf48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91b86561f4104483950975ef86392d99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5abe9f047c6a41ae993c573eaed0d545",
       "IPY_MODEL_2111de1165994cdd92de7c4bcada70c5",
       "IPY_MODEL_b5e9da04d41c49d98c46f62eb853552e"
      ],
      "layout": "IPY_MODEL_7c1cf5dc645443e4a98423fdd44fc2ac"
     }
    },
    "5abe9f047c6a41ae993c573eaed0d545": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92ebd24713844920ad8f5bf5b3c26bac",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_5325d2586ded4bb19ec4ad6794bc82a5",
      "value": "tokenizer.model:\u2007100%"
     }
    },
    "2111de1165994cdd92de7c4bcada70c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6708e1a5ecde4f6694022870a59599d8",
      "max": 4689074,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4ecbdfdbcb6141fb9b855eea88ee5bd7",
      "value": 4689074
     }
    },
    "b5e9da04d41c49d98c46f62eb853552e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22ecf0ded39a49dd9a18b78f18af7d9f",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_33a1edb2e7574af6818174bf410f4f58",
      "value": "\u20074.69M/4.69M\u2007[00:02&lt;00:00,\u20071.81MB/s]"
     }
    },
    "7c1cf5dc645443e4a98423fdd44fc2ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92ebd24713844920ad8f5bf5b3c26bac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5325d2586ded4bb19ec4ad6794bc82a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6708e1a5ecde4f6694022870a59599d8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ecbdfdbcb6141fb9b855eea88ee5bd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "22ecf0ded39a49dd9a18b78f18af7d9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33a1edb2e7574af6818174bf410f4f58": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1eb9104bdba246efbf32c6e9da05edd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7cb5cd3802834333b19c139f863345c3",
       "IPY_MODEL_1dda69889295462c9a4500f40a659234",
       "IPY_MODEL_81ce7f3e35c843db9d1840a6a7147c8a"
      ],
      "layout": "IPY_MODEL_453b200bd8054b99bd47acfa34993977"
     }
    },
    "7cb5cd3802834333b19c139f863345c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb291aa2e4054541b282f444a0f3cf2b",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_601c4916141541f6ac1483beae60ce8e",
      "value": "tokenizer.json:\u2007100%"
     }
    },
    "1dda69889295462c9a4500f40a659234": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0fd67e126644a6d9990ed4f3d0d931c",
      "max": 33384568,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ffeb9dc4e094fa18d888ccdc4100ce0",
      "value": 33384568
     }
    },
    "81ce7f3e35c843db9d1840a6a7147c8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91a94d909d38413491197f21aa091d45",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_880f12d8b3594dea93bf6fc306ad9b86",
      "value": "\u200733.4M/33.4M\u2007[00:02&lt;00:00,\u200712.2MB/s]"
     }
    },
    "453b200bd8054b99bd47acfa34993977": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb291aa2e4054541b282f444a0f3cf2b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "601c4916141541f6ac1483beae60ce8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0fd67e126644a6d9990ed4f3d0d931c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ffeb9dc4e094fa18d888ccdc4100ce0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "91a94d909d38413491197f21aa091d45": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "880f12d8b3594dea93bf6fc306ad9b86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e18d03eb76de4aa3a9e0d528a2e65779": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_37a9927190424b769454b55b53ecede4",
       "IPY_MODEL_58956129576943b38ee7ff8be53b5e4a",
       "IPY_MODEL_5dfbee4627434f64a08c267fd22ce7e1"
      ],
      "layout": "IPY_MODEL_3f01a807fd934cc6bb045f0c9c0e9084"
     }
    },
    "37a9927190424b769454b55b53ecede4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22f21c33284c460eb423bbec6da667c2",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_7fdae87d1c8d4e24b4daf09069167786",
      "value": "added_tokens.json:\u2007100%"
     }
    },
    "58956129576943b38ee7ff8be53b5e4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd6ace9fc11e4c8da14b5fc28a4767ad",
      "max": 35,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3bc0fba72f3940b5b24da834498e12d1",
      "value": 35
     }
    },
    "5dfbee4627434f64a08c267fd22ce7e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdab6f11dd524ccd8d6cb3d3f30a588f",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_b699744bac1f4318bea77409d6f3ba1b",
      "value": "\u200735.0/35.0\u2007[00:00&lt;00:00,\u20072.57kB/s]"
     }
    },
    "3f01a807fd934cc6bb045f0c9c0e9084": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22f21c33284c460eb423bbec6da667c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fdae87d1c8d4e24b4daf09069167786": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd6ace9fc11e4c8da14b5fc28a4767ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bc0fba72f3940b5b24da834498e12d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fdab6f11dd524ccd8d6cb3d3f30a588f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b699744bac1f4318bea77409d6f3ba1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4475b348e48a4ef9a2b243190dfba781": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_de472911130d464e89c47c1684a939c3",
       "IPY_MODEL_dc7c7e0dca534215a6054ad39a75b131",
       "IPY_MODEL_bbd5c38aca3345afb512ededf1a07f93"
      ],
      "layout": "IPY_MODEL_6f008b4ed0564a9b92e3f91e70ce214e"
     }
    },
    "de472911130d464e89c47c1684a939c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e52c443f40fb47d18604b3ecdd0c7289",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_326ed04522c248e3bfb01f8d3d28e96d",
      "value": "special_tokens_map.json:\u2007100%"
     }
    },
    "dc7c7e0dca534215a6054ad39a75b131": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f87ac4fb4fc245a884796682269d727f",
      "max": 670,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7126af9fe41249499cc90d2c533afd82",
      "value": 670
     }
    },
    "bbd5c38aca3345afb512ededf1a07f93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aeb5a52fd11a4583b20a4ecb45769e50",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_90338b57c5c945968bd7d6190bd780c2",
      "value": "\u2007670/670\u2007[00:00&lt;00:00,\u200764.7kB/s]"
     }
    },
    "6f008b4ed0564a9b92e3f91e70ce214e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e52c443f40fb47d18604b3ecdd0c7289": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "326ed04522c248e3bfb01f8d3d28e96d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f87ac4fb4fc245a884796682269d727f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7126af9fe41249499cc90d2c533afd82": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aeb5a52fd11a4583b20a4ecb45769e50": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90338b57c5c945968bd7d6190bd780c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ffd338bb71164c79adbd129fd8cd08a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_97b2994652194dba8bb4d66659512aae",
       "IPY_MODEL_e0ebd7319c294a0bae43baf1c577ab05",
       "IPY_MODEL_b11c94fee7434f53956d7da3317753ad"
      ],
      "layout": "IPY_MODEL_064993a00d9042c590b7970412df61c7"
     }
    },
    "97b2994652194dba8bb4d66659512aae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a44b5f778350495699bb7cebb6227b77",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_eb4ffe32d0f949bfa2db46ad3a2f3028",
      "value": "Map:\u2007100%"
     }
    },
    "e0ebd7319c294a0bae43baf1c577ab05": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ab03296d27247c9a51f7ba8dd999a4a",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b8e09799edf7414bba5c89a34298dfae",
      "value": 2000
     }
    },
    "b11c94fee7434f53956d7da3317753ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acac194985cb4745b105b930559144f7",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_775a43c3274a4c2aa7fe0259c4919d89",
      "value": "\u20072000/2000\u2007[00:00&lt;00:00,\u200717707.81\u2007examples/s]"
     }
    },
    "064993a00d9042c590b7970412df61c7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a44b5f778350495699bb7cebb6227b77": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb4ffe32d0f949bfa2db46ad3a2f3028": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ab03296d27247c9a51f7ba8dd999a4a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8e09799edf7414bba5c89a34298dfae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "acac194985cb4745b105b930559144f7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775a43c3274a4c2aa7fe0259c4919d89": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8c86903669a4ef2874f810631c0097d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4c0f729ddce54273b73f759b4cb6835e",
       "IPY_MODEL_46550dbb3fcc46ac96edfd73765c511b",
       "IPY_MODEL_850bbea25b5b4ef9bc930245bf9065be"
      ],
      "layout": "IPY_MODEL_99a6432d73534186a142fec8a6948133"
     }
    },
    "4c0f729ddce54273b73f759b4cb6835e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba586d565942430db4ddfc67ebf259fc",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_b6f5642ea4cb40d5994896dff7cab04f",
      "value": "Map:\u2007100%"
     }
    },
    "46550dbb3fcc46ac96edfd73765c511b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbc1735d8d5f4491aa8d129e7b2b3f09",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f3c1e502955746388f41e3cbcfeba76b",
      "value": 20
     }
    },
    "850bbea25b5b4ef9bc930245bf9065be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c97f702877324a8d97a08362451a6d21",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_0fb27a8bbabd4dd3bb34bc5a07611ab1",
      "value": "\u200720/20\u2007[00:00&lt;00:00,\u2007937.98\u2007examples/s]"
     }
    },
    "99a6432d73534186a142fec8a6948133": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba586d565942430db4ddfc67ebf259fc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6f5642ea4cb40d5994896dff7cab04f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dbc1735d8d5f4491aa8d129e7b2b3f09": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3c1e502955746388f41e3cbcfeba76b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c97f702877324a8d97a08362451a6d21": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fb27a8bbabd4dd3bb34bc5a07611ab1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
